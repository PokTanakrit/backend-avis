# from flask import Flask, request, jsonify
# import requests
# from connected_milvus import connect_to_milvus, get_embedding, search_cosine
# from sklearn.metrics.pairwise import cosine_similarity
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import numpy as np
# from flask_cors import CORS



# app = Flask(__name__)
# CORS(app)  # Enable CORS for all routes
# llm_url = "https://1438-202-44-40-186.ngrok-free.app/textgenerate"

# # Load the Hugging Face model and tokenizer
# tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-reranker-v2-m3")
# model = AutoModelForSequenceClassification.from_pretrained("BAAI/bge-reranker-v2-m3").to("cuda:0")

# def rerank(query, results):
#     if not isinstance(query, str):
#         raise ValueError("Query should be a string.")
    
#     input_texts = [result['text'] for result in results]
#     if not all(isinstance(text, str) for text in input_texts):
#         raise ValueError("Each result text should be a string.")
    
#     # Tokenize input pairs and ensure tensors are on the GPU
#     inputs = tokenizer([query] * len(input_texts), input_texts, padding=True, truncation=True, return_tensors="pt").to("cuda:0")
#     outputs = model(**inputs)

#     logits = outputs.logits
#     if logits.shape[1] == 1:
#         scores = torch.sigmoid(logits).squeeze().detach().cpu().numpy()
#     else:
#         scores = torch.nn.functional.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()

#     for i, result in enumerate(results):
#         result['score'] = float(scores[i])
#     reranked_results = sorted(results, key=lambda x: x['score'], reverse=True)
    
#     return reranked_results

# def calculate_similarity_between_context_and_generated(generated_texts):
#     """
#     Calculate cosine similarity between returned_context and generated_text.

#     Args:
#         generated_texts: A list of dictionaries with 'text' and 'generated_response' keys.

#     Returns:
#         A list of generated_texts with updated similarity scores between returned_context and generated_text.
#     """
#     for result in generated_texts:
#         context_vector = get_embedding(result['text'])
#         generated_text_vector = get_embedding(result['generated_response'])
#         similarity_score = cosine_similarity([context_vector], [generated_text_vector])[0][0]
#         result['similarity_score'] = similarity_score

#     # Sort the results based on similarity score in descending order
#     return sorted(generated_texts, key=lambda x: x['similarity_score'], reverse=True)

# @app.route('/searchindex3', methods=['POST'])
# def searchretruval():
#     try:
#         connect_to_milvus()
        
#         data = request.get_json()
#         if 'text' not in data:
#             return jsonify({"error": 'Key "text" not found in the data'}), 400

#         text = data['text']
#         print(f"Received text for search (Cosine): {text}")

#         query_vector = get_embedding(text)

#         results = search_cosine("course_information", query_vector)
        
#         if results:
#             reranked_results = rerank(text, results)
#             generate_text = []
            
#             for result in reranked_results[:3]:  # Take top 5 reranked results
#                 relevant_data = result['text']
#                 print(f"relevant_data: {relevant_data}")
#                 response = requests.post(llm_url, json={"input_text": text, "context": relevant_data})
#                 if response.status_code == 200:
#                     generated_text = response.json().get("generated_text", "")
#                     returned_context = response.json().get("context", "")
                    
#                     generate_text.append({
#                         "text": returned_context,
#                         "generated_response": generated_text
#                     })
#                 else:
#                     print("Error generating response from LLM")
            
#             # # Calculate similarity between returned_context and generated_text
#             # final_reranked_results = calculate_similarity_between_context_and_generated(generate_text)

#             return jsonify({"responses": generate_text[0]}), 200
#         else:
#             return jsonify({"message": "No results found."}), 404

#     except Exception as e:
#         print(f"Error: {e}")
#         return jsonify({"error": "An error occurred while processing the request."}), 500

# if __name__ == '__main__':
#     app.run(port=3000)

import re
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus.common import thai_stopwords

# ‡πÇ‡∏´‡∏•‡∏î stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
thai_stopwords = set(thai_stopwords())


import re
from pythainlp.tokenize import word_tokenize

def clean_text(text):
    """ ‡∏•‡∏ö \n, HTML Tags, ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏≥‡πÑ‡∏ß‡πâ """
    text = re.sub(r'\s+', ' ', text)  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡∏ä‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞ \n
    text = re.sub(r'[\'"]', '', text)  # ‡∏•‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢ " ‡πÅ‡∏•‡∏∞ '

    # text = re.sub(r'<.*?>', '', text)  # ‡∏•‡∏ö HTML tags ‡πÄ‡∏ä‡πà‡∏ô <p>...</p>
    # text = re.sub(r'\d+\.\d+|\d+', '', text)  # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠ ‡πÄ‡∏ä‡πà‡∏ô 5.1, 7.2, 2564
    # text = re.sub(r'[^\u0E00-\u0E7F\w\s]', '', text)  # ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

    return text.strip()  # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏±‡∏ß‡∏ó‡πâ‡∏≤‡∏¢

# üîπ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
text = """
"2 \n \n5. ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå \n5.1  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏ó‡∏§‡∏©‡∏é‡∏µ‡πÅ‡∏•‡∏∞‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÇ‡∏î‡∏¢\n‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏µ‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û  \n5.2  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÉ‡∏ô‡∏ï‡∏•‡∏≤‡∏î‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏≤‡∏ô‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥  \n5.3  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏¢‡∏≤‡∏¢‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ï‡πà‡∏≠‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï \n5.4  ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏ò‡∏£‡∏£‡∏° ‡∏à‡∏£‡∏£‡∏¢‡∏≤‡∏ö‡∏£‡∏£‡∏ì ‡πÅ‡∏•‡∏∞‡πÄ‡∏à‡∏ï‡∏Ñ‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û  \n \n6. ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£ \n \n‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ß‡∏¥‡∏ä‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå (‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‡∏û.‡∏®. 2564) ‡πÇ‡∏î‡∏¢\n‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏™‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤ \n \n7. ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ï‡πà‡∏≠ \n7.1 ‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏™ ‡∏≤‡πÄ‡∏£‡πá‡∏à‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ï‡∏≠‡∏ô‡∏õ‡∏•‡∏≤‡∏¢ (‡∏°.6) ‡∏´‡∏£‡∏∑‡∏≠  \n7.2 ‡∏™ ‡∏≤‡πÄ‡∏£‡πá‡∏à‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ô‡∏µ‡∏¢‡∏ö‡∏±‡∏ï‡∏£‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û (‡∏õ‡∏ß‡∏ä.) ‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ò‡∏¥‡∏Å‡∏≤‡∏£\n‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á \n7.3 ‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏û‡∏£‡∏∞‡∏à‡∏≠‡∏°‡πÄ‡∏Å‡∏•‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‡∏ß‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤\n‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï \n \n8. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô \n \n‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©  ‡πÇ‡∏î‡∏¢‡∏Å ‡∏≤‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô\n‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ï‡∏•‡∏≠‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ 50 (‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 64 ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï) ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞ 40 (‡πÑ‡∏°‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 36.4 ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏¥‡∏ï) \n \n‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤\n‡πÑ‡∏î‡πâ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ú‡∏•‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© TOEIC (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤) ‡πÑ‡∏°‡πà‡∏ï‡πà ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 550 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô  \n \n9. ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \n \n‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏≠‡∏∏‡∏î‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (Admission) ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£\n‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤
"""
print(clean_text(text))
